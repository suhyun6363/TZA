{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMclhr9xTGljRg+Nh4HruQk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suhyun6363/TZA/blob/oliveyoung_recommend/%EC%B6%94%EC%B2%9C%EB%8D%B0%EC%9D%B4%ED%83%80~!.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ON2tDBcl0iEg"
      },
      "outputs": [],
      "source": [
        "# 1. 크롤링\n",
        "# 리뷰평균점수, moisturizing 추가.ver\n",
        "\n",
        "# https://github.com/dev-dain/Lalavla-Crawling/blob/master/crawling.py 참고\n",
        "\n",
        "from selenium import webdriver                 # pip install selenium 설치 필요\n",
        "                                               # 2023년 기준 selenium ver.4.x 설치됨\n",
        "from selenium.webdriver.common.by import By    # 4.x 버전 이후 find_element호출 방식이 변경되어 추가\n",
        "import time                                    # sleep() 함수 사용을 위해 추가\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from collections import OrderedDict\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
        "\n",
        "\n",
        "\n",
        "url = 'https://www.oliveyoung.co.kr/store/display/getMCategoryList.do?dispCatNo='\n",
        "data = OrderedDict()\n",
        "\n",
        "beauty_list = {\n",
        " 'makeup': {\n",
        "    '베이스메이크업': {\n",
        "        '블러셔': '1000001000200010006'\n",
        "    },\n",
        "    '립메이크업': {\n",
        "        '립틴트': '1000001000200060003',\n",
        "        '립스틱': '1000001000200060004',\n",
        "        '틴티드_립밤': '1000001000200060001',\n",
        "        '립글로스': '1000001000200060002'\n",
        "    },\n",
        "    '아이메이크업': {\n",
        "        '아이셰도우': '1000001000200070003'\n",
        "    }\n",
        "}\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# 브라우저 꺼짐 방지 옵션\n",
        "chrome_options = Options()\n",
        "chrome_options.add_experimental_option(\"detach\", True)\n",
        "# 크롬 드라이버 생성\n",
        "driver = webdriver.Chrome('C:/Users/DS/PycharmProjects/Lalavla-Crawling/driver/chromedriver.exe')\n",
        "\n",
        "def clean_product_name(product_name):\n",
        "    # 대소문자를 무시하고 숫자 + colors 또는 color를 찾아 삭제\n",
        "    # pattern_to_remove = r'\\d+\\s*colors?'\n",
        "    pattern_to_remove = r'\\b\\d+(\\.\\d+)?\\s*colors?\\b|\\b\\d+(\\.\\d+)?[gm]|\\b[NEW]\\b|\\b\\d+\\.\\s*|\\bl\\b'\n",
        "\n",
        "\n",
        "    # 대소문자 무시 플래그 추가\n",
        "    product_name = re.sub(pattern_to_remove, '', product_name, flags=re.IGNORECASE)\n",
        "\n",
        "    patterns_to_remove = [\n",
        "        r'\\([^)]*\\)',  # (내용)\n",
        "        r'\\[[^]]*\\]',  # [내용]\n",
        "        r'\\d+종',\n",
        "        r'택\\s*\\d+',  # 택 + 숫자 (예: 택 1, 택1)\n",
        "        r'[+]',  # + (예: 1+1)\n",
        "        r'\\d+g',  # 숫자 + g (예: 4g)\n",
        "        r'\\d+\\.\\d+g',  # 숫자 + 소수점 + 숫자 + g (예: 4.8g)\n",
        "        r'\\d+ml',  # 숫자 + m 또는 M + g 또는 G (예: 4ml)\n",
        "        r'\\d+\\.\\d+ml',  # 숫자 + 소수점 + 숫자 + g (예: 4.8ml)\n",
        "        r'AD',\n",
        "        r'ad',\n",
        "        r'단품',\n",
        "        r'기획',\n",
        "        r'한정기획',\n",
        "        r'기획세트',\n",
        "        r'NEW',\n",
        "        r'/',           # / (예: /)\n",
        "    ]\n",
        "\n",
        "    # 각 패턴을 순회하며 삭제\n",
        "    for pattern in patterns_to_remove:\n",
        "        product_name = re.sub(pattern, '', product_name)\n",
        "\n",
        "    # 중복 공백 제거\n",
        "    product_name = ' '.join(product_name.split())\n",
        "\n",
        "    return product_name\n",
        "\n",
        "def get_product_info(small_list, category):\n",
        "    '''\n",
        "    category_list : list(String). 해당 상품의 대/중/소/카테고리     # ex) 메이크업 > 립메이크업(small) > 립틴트(category)\n",
        "    name : String. 상품 이름\n",
        "    number : String. 상품 고유번호\n",
        "    brand : String. 브랜드 이름\n",
        "    img : String (src). 대표 이미지 -> 복수 개일 수 있으므로 변경 필요\n",
        "    product_img_list : list(String). 대표 이미지들의 리스트\n",
        "    is_discount : boolean. 할인 여부\n",
        "    origin_price : String (**원). 정상가\n",
        "    discount_price : String (**원). 할인 가격\n",
        "    average_rate : 리뷰평균\n",
        "\n",
        "    옵션이 없는 단일 상품의 경우, 옵션 개수를 0개로 할 것인가 1개로 할 것인가\n",
        "    그리고 옵션 이름 목록과 가격에 그냥 name과 price를 넣어야 하나?\n",
        "    품절의 경우 옵션 가격은 얼마?\n",
        "\n",
        "    option_count : String. 옵션 개수\n",
        "    option_name_list : list(String). 옵션별 이름\n",
        "    option_price_list : list(String). 옵션별 가격\n",
        "    option_img_list : list(String). 옵션별 이미지 src -> colorchip_list\n",
        "    '''\n",
        "\n",
        "    time.sleep(0.5)\n",
        "\n",
        "    element_present = EC.presence_of_element_located(\n",
        "        (By.CSS_SELECTOR, 'a.goods_reputation[data-attr=\"상품상세^상품상세_SortingTab^리뷰\"]'))\n",
        "\n",
        "    WebDriverWait(driver, timeout=10).until(element_present)\n",
        "\n",
        "    # '리뷰' 링크 클릭\n",
        "    driver.find_element(By.CSS_SELECTOR, 'a.goods_reputation[data-attr=\"상품상세^상품상세_SortingTab^리뷰\"]').click()\n",
        "    WebDriverWait(driver, timeout=10).until(element_present)\n",
        "\n",
        "    '''\n",
        "    moisturizing\n",
        "    moisturizing_1 : 아주 촉촉해요\n",
        "    moisturizing_2 : 보통이에요\n",
        "    moisturizing_3 : 매트해요\n",
        "\n",
        "    '''\n",
        "\n",
        "\n",
        "    moisturizing_1_raw = None\n",
        "    moisturizing_2_raw = None\n",
        "    moisturizing_3_raw = None\n",
        "\n",
        "    try:\n",
        "        moisturizing_1_raw = WebDriverWait(driver, 10).until(\n",
        "            EC.presence_of_element_located(\n",
        "                (By.XPATH, '//*[@id=\"gdasContentsArea\"]/div/div[3]/dl[4]/dd/ul/li[1]/em'))\n",
        "        ).text\n",
        "    except (TimeoutException, NoSuchElementException):\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        moisturizing_2_raw = WebDriverWait(driver, 10).until(\n",
        "            EC.presence_of_element_located(\n",
        "                (By.XPATH, '//*[@id=\"gdasContentsArea\"]/div/div[3]/dl[4]/dd/ul/li[2]/em'))\n",
        "        ).text\n",
        "    except (TimeoutException, NoSuchElementException):\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        moisturizing_3_raw = WebDriverWait(driver, 10).until(\n",
        "            EC.presence_of_element_located(\n",
        "                (By.XPATH, '//*[@id=\"gdasContentsArea\"]/div/div[3]/dl[4]/dd/ul/li[3]/em'))\n",
        "        ).text\n",
        "    except (TimeoutException, NoSuchElementException):\n",
        "        pass\n",
        "\n",
        "    moisturizing_1 = moisturizing_1_raw.replace('%', '') if moisturizing_1_raw else \"0\"\n",
        "    moisturizing_2 = moisturizing_2_raw.replace('%', '') if moisturizing_2_raw else \"0\"\n",
        "    moisturizing_3 = moisturizing_3_raw.replace('%', '') if moisturizing_3_raw else \"0\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    number = driver.find_element_by_class_name('prd_btn_area > .btnZzim') \\\n",
        "        .get_attribute('data-ref-goodsno')\n",
        "    img = (driver.find_element_by_id('mainImg')).get_attribute('src')\n",
        "    brand = (driver.find_element_by_class_name('prd_brand')).text\n",
        "    name = (driver.find_element_by_class_name('prd_name')).text\n",
        "    # 정규표현식을 사용하여 대괄호와 대괄호 안의 내용 삭제\n",
        "    name = clean_product_name(name)\n",
        "    try:\n",
        "        # WebDriverWait를 사용하여 요소가 나타날 때까지 대기\n",
        "        average_rate_elem = WebDriverWait(driver, 10).until(\n",
        "            EC.presence_of_element_located((By.CSS_SELECTOR, '#repReview > b'))\n",
        "        )\n",
        "        average_rate = average_rate_elem.text\n",
        "    except (TimeoutException, NoSuchElementException):\n",
        "        average_rate = None\n",
        "        print(\"No average rate found for this product.\")\n",
        "\n",
        "    # average_rate = driver.find_elements_by_css_selector('# repReview > b')\n",
        "    # repReview > b\n",
        "\n",
        "    cat = driver.find_elements_by_class_name('loc_history > li > .cate_y')\n",
        "    category_list = [c.text for c in cat]\n",
        "\n",
        "    discount_price = (driver.find_element_by_class_name('price-2')).text.split('\\n')[0]\n",
        "\n",
        "    try:\n",
        "        # 할인 상품인 경우 .price-1 요소가 있음\n",
        "        origin_price = (driver.find_element_by_class_name('price-1')).text.split('\\n')[0]\n",
        "        is_discount = True\n",
        "    except:\n",
        "        # 할인이 아닌 경우 discount_price가 곧 origin_price\n",
        "        # 즉, 어느 경우든 discount_price가 해당 상품의 최종가\n",
        "        origin_price = discount_price\n",
        "        is_discount = False\n",
        "\n",
        "    origin_price = origin_price.replace(',', '')\n",
        "    discount_price = discount_price.replace(',', '')\n",
        "\n",
        "    option_name_list = []\n",
        "    option_price_list = []\n",
        "    option_img_list = []\n",
        "\n",
        "    try:\n",
        "        # 옵션이 없는 경우 .prd_option_box 요소가 없음 (except로 넘어감)\n",
        "        # .prd_option_box를 클릭해야 .option_value가 드러남\n",
        "        driver.find_element_by_class_name('prd_option_box').click()\n",
        "\n",
        "        # 품절 상품인 경우 .type1 soldout임\n",
        "        options = driver.find_elements_by_class_name('type1 > a > div > .option_value')\n",
        "\n",
        "        if not options:  # 옵션에 상품 이미지가 없는 경우 .type1 없이 <li class> 태그임\n",
        "            # options 자체는 WebElement가 요소인 리스트임. option들을 가진 리스트\n",
        "            options = driver.find_elements_by_tag_name('li > a > div > .option_value')\n",
        "\n",
        "        # 옵션명, 가격이 차례로 요소로 들어간 리스트가 option_values가 됨\n",
        "        # ex) ['04 데일리톡(리뉴얼)', '7,840원']\n",
        "        # 이 때, 품절 상품의 경우 상품 이름만 요소로 들어감. 옵션 자체에 가격이 없음\n",
        "        option_values = [option.text.split('\\n') for option in options]\n",
        "\n",
        "        # 상품의 옵션 이름만 리스트로 뽑아옴\n",
        "        option_name_list = [option[0] for option in option_values]\n",
        "        option_count = len(options)\n",
        "\n",
        "        for k in range(len(option_name_list)):\n",
        "            option_name = option_name_list[k]\n",
        "            # 품절일 경우, 기본가인 discount_price를 품절 상품 가격으로 둠\n",
        "            if option_name.find('(품절)') != -1:\n",
        "                option_price_list.append(discount_price)\n",
        "            else:\n",
        "                option_price_list.append(option_values[k][1].rstrip('원'))\n",
        "        option_name_list = [clean_product_name(option[0]) for option in option_values]\n",
        "\n",
        "        # 옵션은 있으나 옵션에 이미지가 없는 경우 except로 넘어감\n",
        "        # 옵션에 이미지가 있는 경우에만 option_img_list에 각 이미지를 넣음\n",
        "        option_imgs = driver.find_elements_by_class_name('type1 > a > span > img')\n",
        "        option_img_list = [img.get_attribute('src') for img in option_imgs]\n",
        "\n",
        "    except:\n",
        "        # 품절일 때 option_count = 0이 돼서 가격이 안 나옴\n",
        "        option_count = 0\n",
        "\n",
        "    data[\"category_list\"] = category_list\n",
        "    data[\"name\"] = name\n",
        "    data[\"number\"] = number\n",
        "    data[\"brand\"] = brand\n",
        "    data[\"img\"] = img\n",
        "    data[\"average_rate\"] = average_rate\n",
        "    data[\"is_discount\"] = is_discount\n",
        "    data[\"origin_price\"] = origin_price\n",
        "    data[\"discount_price\"] = discount_price\n",
        "    data[\"option_count\"] = option_count\n",
        "    data[\"option_name_list\"] = option_name_list\n",
        "    data[\"option_price_list\"] = option_price_list\n",
        "    data[\"colorchip_list\"] = option_img_list\n",
        "    data[\"moisturizing_1\"] = moisturizing_1\n",
        "    data[\"moisturizing_2\"] = moisturizing_2\n",
        "    data[\"moisturizing_3\"] = moisturizing_3\n",
        "\n",
        "\n",
        "    try:\n",
        "        if len(data[\"colorchip_list\"]) > 0:\n",
        "            print(data)\n",
        "            with open(\n",
        "                    './data/{0}/{1}/{2}.json'.format(small_list, category, number),\n",
        "                    'w', encoding='utf-8') as f:\n",
        "                json.dump(data, f, ensure_ascii=False, indent=\"\\t\")\n",
        "    except:  # 디렉터리가 없을 때만 디렉터리를 만듦\n",
        "        os.makedirs('./data/{0}/{1}'.format(small_list, category))\n",
        "\n",
        "    driver.back()  # 뒤로가기\n",
        "    time.sleep(0.5)\n",
        "\n",
        "for small_list in beauty_list['makeup']:  # small_list는 String\n",
        "    for category in beauty_list['makeup'][small_list]:  # category는 String\n",
        "        driver.get(url + beauty_list['makeup'][small_list][category])\n",
        "        driver.implicitly_wait(1)\n",
        "        count = 0  # count로 몇 번째 item의 정보를 가져올지 정함\n",
        "\n",
        "        # 상품을 감싼 태그를 빼냄. 24/36/48개\n",
        "        items = driver.find_elements_by_xpath('//li[@criteo-goods]')\n",
        "\n",
        "        for index in range(len(items)):\n",
        "            # 개별 아이템을 고름\n",
        "            item = driver.find_element_by_xpath(\n",
        "                '//*[@id=\"Contents\"]/ul[%s]/li[%s]/div/a'\n",
        "                % ((count // 4) + 2, (count % 4) + 1)\n",
        "            )\n",
        "            item.click()\n",
        "            get_product_info(small_list, category)\n",
        "            count += 1\n",
        "\n",
        "        page_index = 0\n",
        "        # #Container > div.pageing > a:nth-child(2)\n",
        "        pages = driver.find_elements_by_css_selector('#Container > div.pageing > a')\n",
        "        pages_count = len(pages)\n",
        "        if pages_count > 0:\n",
        "            while True:\n",
        "                pages = driver.find_elements_by_css_selector('#Container > div.pageing > a')\n",
        "                pages[page_index].click()\n",
        "                time.sleep(0.5)\n",
        "                count = 0  # count로 몇 번째 item의 정보를 가져올지 정함\n",
        "\n",
        "                # 상품을 감싼 태그를 빼냄. 24/36/48개\n",
        "                items = driver.find_elements_by_xpath('//li[@criteo-goods]')\n",
        "\n",
        "                for index in range(len(items)):\n",
        "                    # 개별 아이템을 고름\n",
        "                    item = driver.find_element_by_xpath(\n",
        "                        '//*[@id=\"Contents\"]/ul[%s]/li[%s]/div/a'\n",
        "                        % ((count // 4) + 2, (count % 4) + 1)\n",
        "                    )\n",
        "                    item.click()\n",
        "                    get_product_info(small_list, category)\n",
        "                    count += 1\n",
        "\n",
        "                page_index += 1\n",
        "\n",
        "                # 마지막 페이지인 경우 종료\n",
        "                if page_index == pages_count:\n",
        "                    break\n",
        "\n",
        "driver.quit()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. k-means로 RGB구하고 v,b,s로 변환 + moisturizing\n",
        "# 위에서 크롤링한 색상표 > 클러스터링 후 RGB값을 구하기 + moisturizing 계산 > csv형태로 저장\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import csv\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "import json\n",
        "import sys\n",
        "import colorsys\n",
        "from skimage.color import rgb2lab\n",
        "from colormath.color_objects import sRGBColor, LabColor, HSVColor\n",
        "from colormath.color_conversions import convert_color\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# JSON 파일을 읽어서 product_info_list를 생성하는 함수\n",
        "def read_json_files(base_folder, categories):\n",
        "    product_info_list = []\n",
        "\n",
        "    for category in categories:\n",
        "        category_folder = os.path.join(base_folder, category)\n",
        "        subcategories = [f for f in os.listdir(category_folder) if os.path.isdir(os.path.join(category_folder, f))]\n",
        "\n",
        "        for subcategory in subcategories:\n",
        "            subcategory_folder = os.path.join(category_folder, subcategory)\n",
        "            json_files = [f for f in os.listdir(subcategory_folder) if\n",
        "                          f.endswith('.json') and not f.startswith('.DS_Store')]\n",
        "\n",
        "            for json_file in json_files:\n",
        "                json_file_path = os.path.join(subcategory_folder, json_file)\n",
        "\n",
        "                with open(json_file_path, 'r', encoding='utf-8') as file:\n",
        "                    product_info = json.load(file)\n",
        "                    product_info_list.append(product_info)\n",
        "\n",
        "    return product_info_list\n",
        "\n",
        "\n",
        "# 기존 데이터 예시와 유사한 구조의 폴더 구조\n",
        "base_folder = \"C:\\\\Users\\\\DS\\\\PycharmProjects\\\\Lalavla-Crawling\\\\data\"\n",
        "categories = [\n",
        "    \"립메이크업\",\n",
        "    \"베이스메이크업\",\n",
        "    \"아이메이크업\",\n",
        "]\n",
        "\n",
        "# 모든 JSON 파일을 읽어서 product_info_list를 생성\n",
        "product_info_list = read_json_files(base_folder, categories)\n",
        "\n",
        "\n",
        "# 이미지 클러스터링 및 RGB 값 계산 함수\n",
        "def calculate_option_name_rgb(colorchip_url):\n",
        "    response = requests.get(colorchip_url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "\n",
        "    # 이미지를 RGB 형식으로 변환 (채널 수가 4인 경우, RGBA에서 A 제거)\n",
        "    img = img.convert(\"RGB\")\n",
        "    img_array = np.array(img)\n",
        "\n",
        "    # 허용 오차 설정\n",
        "    tolerance = 30\n",
        "\n",
        "    # [0, 0, 0] 및 [255, 255, 255]의 근처값을 제거하는 조건 수정\n",
        "    non_black_and_white_pixels = img_array[\n",
        "        ~np.all(((img_array >= [0, 0, 0]) & (img_array <= [0 + tolerance, 0 + tolerance, 0 + tolerance])) |\n",
        "                ((img_array >= [255 - tolerance, 255 - tolerance, 255 - tolerance]) & (img_array <= [255, 255, 255])),\n",
        "                axis=-1)]\n",
        "\n",
        "    # 이미지를 2D 배열로 변환\n",
        "    face_data = non_black_and_white_pixels.reshape((-1, 3))\n",
        "\n",
        "    # 데이터가 비어 있는 경우 건너뛰기\n",
        "    if face_data.size == 0:\n",
        "        print(\"No valid data available after filtering. Skipping...\")\n",
        "        return None\n",
        "\n",
        "    # 표준화 (Standardization) - 평균이 0, 표준편차가 1이 되도록 스케일 조정\n",
        "    scaler = StandardScaler()\n",
        "    face_data_scaled = scaler.fit_transform(face_data)\n",
        "\n",
        "    # 최적의 k 값으로 k-means 클러스터링 수행\n",
        "    optimal_k = 4\n",
        "    optimal_kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "    optimal_cluster_labels = optimal_kmeans.fit_predict(face_data_scaled)\n",
        "\n",
        "    # 클러스터 중심값(RGB 형식) 출력\n",
        "    cluster_centers_rgb = scaler.inverse_transform(optimal_kmeans.cluster_centers_)\n",
        "\n",
        "    # 가장 픽셀 수가 많은 클러스터 찾기\n",
        "    most_pixels_cluster = max(Counter(optimal_cluster_labels), key=Counter(optimal_cluster_labels).get)\n",
        "\n",
        "    # 가장 픽셀 수가 많은 클러스터의 RGB 값 출력\n",
        "    most_pixels_cluster_rgb = cluster_centers_rgb[most_pixels_cluster]\n",
        "    print(f'Most Pixels Cluster RGB for option {option_name}: {most_pixels_cluster_rgb}')\n",
        "\n",
        "    return most_pixels_cluster_rgb.tolist()\n",
        "\n",
        "\n",
        "# RGB 값을 LAB 및 HSV로 변환하는 함수\n",
        "def rgb_to_lab_hsv(rgb):\n",
        "    color_rgb = sRGBColor(rgb[0] / 255.0, rgb[1] / 255.0, rgb[2] / 255.0)\n",
        "\n",
        "    # RGB를 LAB로 변환\n",
        "    color_lab = convert_color(color_rgb, LabColor)\n",
        "    lab_b_value = color_lab.lab_b\n",
        "\n",
        "    # RGB를 HSV로 변환\n",
        "    color_hsv = convert_color(color_rgb, HSVColor)\n",
        "    hsv_v_value = color_hsv.hsv_v\n",
        "    hsv_s_value = color_hsv.hsv_s\n",
        "\n",
        "    return lab_b_value, hsv_v_value, hsv_s_value\n",
        "\n",
        "\n",
        "# 결과를 저장할 리스트 초기화\n",
        "results = []\n",
        "\n",
        "# 이미지 URL을 사용하여 option_name별 RGB 값을 계산하고 결과 리스트에 추가\n",
        "for product_info in product_info_list:\n",
        "    option_name_list = product_info.get(\"option_name_list\", [])\n",
        "    colorchip_list = product_info.get(\"colorchip_list\", [])\n",
        "\n",
        "    # 카테고리 리스트 분할\n",
        "    categories = product_info.get(\"category_list\", [])\n",
        "    category_list1 = categories[0] if len(categories) > 0 else ''\n",
        "    category_list2 = categories[1] if len(categories) > 1 else ''\n",
        "    category_list3 = categories[2] if len(categories) > 2 else ''\n",
        "\n",
        "    # 수분 지수 비교\n",
        "    moisturizing_1 = int(product_info.get(\"moisturizing_1\", 0))\n",
        "    moisturizing_2 = int(product_info.get(\"moisturizing_2\", 0))\n",
        "    moisturizing_3 = int(product_info.get(\"moisturizing_3\", 0))\n",
        "\n",
        "    if moisturizing_1 >= moisturizing_2 and moisturizing_1 >= moisturizing_3:\n",
        "        highest_moisturizing_index = 1\n",
        "    else:\n",
        "        highest_moisturizing_index = 2\n",
        "\n",
        "    for option_name, colorchip_url in zip(option_name_list, colorchip_list):\n",
        "        option_rgb = calculate_option_name_rgb(colorchip_url)\n",
        "\n",
        "        if option_rgb is None:\n",
        "            print(f\"Skipping processing for {option_name} due to no valid data.\")\n",
        "            continue  # 다음 option으로 넘어감\n",
        "\n",
        "        # RGB 값을 LAB 및 HSV로 변환\n",
        "        lab_b_value, hsv_v_value, hsv_s_value = rgb_to_lab_hsv(option_rgb)\n",
        "\n",
        "        # moisturizing 업데이트\n",
        "        moisturizing = \"1\" if highest_moisturizing_index == 1 else \"0\"\n",
        "        results.append({\n",
        "            \"category_list1\": category_list1,\n",
        "            \"category_list2\": category_list2,\n",
        "            \"category_list3\": category_list3,\n",
        "            \"name\": product_info.get(\"name\", \"\"),\n",
        "            \"number\": product_info.get(\"number\", \"\"),\n",
        "            \"brand\": product_info.get(\"brand\", \"\"),\n",
        "            \"img\": product_info.get(\"img\", \"\"),\n",
        "            \"average_rate\": product_info.get(\"average_rate\", \"\"),\n",
        "            \"is_discount\": product_info.get(\"is_discount\", \"\"),\n",
        "            \"origin_price\": product_info.get(\"origin_price\", \"\"),\n",
        "            \"discount_price\": product_info.get(\"discount_price\", \"\"),\n",
        "            \"option_count\": product_info.get(\"option_count\", \"\"),\n",
        "            \"option_name\": option_name,\n",
        "            \"option_price\": product_info.get(\"option_price_list\", [])[option_name_list.index(option_name)],\n",
        "            \"option_rgb\": option_rgb,\n",
        "            \"colorchip_url\": colorchip_url,\n",
        "            \"moisturizing\": moisturizing,\n",
        "\n",
        "            \"v\": hsv_v_value,\n",
        "            \"b\": lab_b_value,\n",
        "            \"s\": hsv_s_value\n",
        "        })\n",
        "\n",
        "        print(\"Category List 3:\", category_list3)\n",
        "        print(\"Name:\", product_info.get(\"name\", \"\"))\n",
        "        print(\"Brand:\", product_info.get(\"brand\", \"\"))\n",
        "        print(\"Option:\", option_name)\n",
        "\n",
        "        print(\"v:\", hsv_v_value)\n",
        "        print(\"b:\", lab_b_value)\n",
        "        print(\"s:\", hsv_s_value)\n",
        "        print(\"-----------------------------------------\")\n",
        "\n",
        "# 현재 날짜를 \"YYYYMMDD\" 형식으로 가져오기\n",
        "today = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
        "\n",
        "\n",
        "# 결과를 CSV 파일로 저장\n",
        "csv_file_path = f\"C:\\\\Users\\\\DS\\\\PycharmProjects\\\\Lalavla-Crawling\\\\product_data_{today}.csv\"\n",
        "with open(csv_file_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    fieldnames = [\"category_list1\", \"category_list2\", \"category_list3\", \"name\", \"number\", \"brand\", \"img\", \"average_rate\", \"is_discount\", \"origin_price\",\n",
        "                  \"discount_price\", \"option_count\", \"option_name\", \"option_price\", \"option_rgb\", \"colorchip_url\",\n",
        "                  \"moisturizing\", \"v\", \"b\", \"s\"]\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "\n",
        "    for result in results:\n",
        "        writer.writerow(result)\n",
        "print(csv_file_path)\n",
        "\n",
        "# 프로그램 종료\n",
        "sys.exit()\n",
        "\n"
      ],
      "metadata": {
        "id": "r9wqXYWM0mQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 각 카테고리당 구한 무게중심을 기준으로 퍼컬분류\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "today = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
        "\n",
        "input_csv_file =f\"C:\\\\Users\\\\DS\\\\PycharmProjects\\\\Lalavla-Crawling\\\\product_data_{today}.csv\"\n",
        "# input_csv_file =f\"C:\\\\Users\\\\DS\\\\PycharmProjects\\\\Lalavla-Crawling\\\\product_data_20240528.csv\"\n",
        "\n",
        "df = pd.read_csv(input_csv_file)\n",
        "\n",
        "results = []\n",
        "for index, row in df.iterrows():\n",
        "    category_2 = row['category_list2']\n",
        "    v_value, b_value, s_value = row['v'] * 100, row['b'], row['s'] * 100  # v 및 s 값에 100을 곱합니다\n",
        "\n",
        "\n",
        "    # 무게중심\n",
        "    if category_2 == '립메이크업':\n",
        "        v_weight, b_weight, s_weight = 79, 18, 54\n",
        "    elif category_2 == '베이스메이크업':\n",
        "        v_weight, b_weight, s_weight = 84, 12, 32\n",
        "    elif category_2 == '아이메이크업':\n",
        "        v_weight, b_weight, s_weight = 83, 11, 23\n",
        "    else:\n",
        "        v_weight, b_weight, s_weight = 0, 0, 0\n",
        "\n",
        "    if v_value > v_weight and b_value > b_weight and s_value > s_weight:\n",
        "        result = \"Spring warm bright\"\n",
        "    elif v_value > v_weight and b_value > b_weight and s_value <= s_weight:\n",
        "        result = \"Spring warm light\"\n",
        "    elif v_value > v_weight and b_value <= b_weight and s_value <= s_weight:\n",
        "        result = \"Summer cool light\"\n",
        "    elif v_value <= v_weight and b_value <= b_weight and s_value <= s_weight:\n",
        "        result = \"Summer cool mute\"\n",
        "    elif v_value <= v_weight and b_value > b_weight and s_value <= s_weight:\n",
        "        result = \"Autumn warm mute\"\n",
        "    elif v_value <= v_weight and b_value > b_weight and s_value > s_weight:\n",
        "        result = \"Autumn warm deep\"\n",
        "    elif v_value <= v_weight and b_value <= b_weight and s_value > s_weight:\n",
        "        result = \"Winter cool deep\"\n",
        "    elif v_value > v_weight and b_value <= b_weight and s_value > s_weight:\n",
        "        result = \"Winter cool bright\"\n",
        "\n",
        "    results.append(result)\n",
        "\n",
        "# 분석 결과를 DataFrame에 추가합니다\n",
        "df['result'] = results\n",
        "# 결과를 새로운 CSV 파일로 저장합니다\n",
        "output_csv_path = f\"oliveyoung_analysis_{today}.csv\"\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"분석이 완료되었고, 결과가 {output_csv_path} 파일에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "BnrkWBwX0mTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. 모든 퍼컬이 같은 제품은 퍼컬삭제(케이스가 클러스터링 되는경우 방지)\n",
        "import pandas as pd\n",
        "import datetime\n",
        "today = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
        "\n",
        "# CSV 파일을 데이터프레임으로 읽어옴\n",
        "df = pd.read_csv(\"C:\\\\Users\\\\DS\\\\PycharmProjects\\\\Lalavla-Crawling\\\\oliveyoung_analysis_20240529.csv\")\n",
        "\n",
        "# 이름이 같은 항목을 그룹화하고 결과가 모두 같은 경우 해당 결과를 공백으로 변경\n",
        "for name, group in df.groupby('name'):\n",
        "    if group['result'].nunique() == 1:\n",
        "        df.loc[df['name'] == name, 'result'] = ''\n",
        "\n",
        "# 결과를 새로운 CSV 파일로 저장\n",
        "df.to_csv(\"output.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "Qrco9UUY0mVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "poO8zxR5aKpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "to4aDkaI0mXr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}